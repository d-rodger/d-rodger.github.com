{"pages":[{"tags":"pages","text":"Currently a senior developer at eRezLife , moving their products from PHP to Python + Django + Postgresql. Formerly the technical lead/architect responsible for billing at a leading developer of mobile social networks ( airG ). I have used Perl + Moose, Redis, Cassandra, node.js, beanstalkd (among others) to make things that work. Love developing solutions, prefer open source, diving into nosql, functional programming.","url":"pages/about.html","title":"About"},{"tags":"pages","text":"Favourite or Interesting Books Programming Clean Code is one of a small selection of books that really seems to have captured the ideas needed to keep code from being designed and developed poorly. It will help you both detect and prevent code rot. Bob Martin has been around long enough, along with people like Martin Fowler to have the experience needed to write a book like this. It's one of those core books that every developer should read, and re-read. Algorithms by Robert Sedgewick & Kevin Wayne is a great practical book on algorithms. By this I mean, it presents the material not from a theoretical or analysis point of view, but as here is what you need to know to get this working. Sedgewick has other books covering analysis of algorithms. If you couple this book with the website that includes a vast amount of the book online, and even better, the Algorithms course on Coursera that Sedgewick provides, you are going to immerse yourself in this topic, and come away with deep, practical knowledge. Based heavily on real-world experiences, Algorithm Design Manual, 2nd ed covers the design and analysis of algorithms, and a section on what the author believes are the 75 most important algorithmic problems. Learning A Mind for Numbers is an excellent book on the latest that is known on how to learn (and how not to). Well written, well thought-out, with clear examples. I highly recommend this to anyone looking to improve their learning. There is also an online course available thorugh Coursera that covers the material in the book. Technology In the Department of Mad Scientists , the author take you through a fascinating look at DARPA - The Defense Advanced Research Projects Agency. You may not have heard of DARPA , but among other things, they funded and helped develop something that today is called the Internet… If you have an interest in how big (outlandish) ideas get turned into reality when no one else in the world even thinks it's possible, read this book :-). Fiction When Daemon came out, it quickly became one of my favourite books of all time. It's up there with Cryptonomicon and Neuromancer. I won't give any spoilers, but if you liked Cryptonomicon, you'll probably like this. The author is a techie who has worked in the industry, with some of the larger companies. He has a good grasp on current and near-future tech.","url":"pages/books.html","title":"Books"},{"tags":"Misc, Security","text":"Email and Privacy I've been a long time user of Gmail. I use my gmail address for…well, everything that you need an email address for. But there's a downside to using a free service like Gmail. You are the product - or more specfically data about you is the product - and it's being packaged and sold over and over and over…and it's also being scooped up by governments for ‘security' (but really, domestic surveillance). Of course, governments contract that stuff out, so it's really…anyone could be accessing your data. So what to do about it? For starters, I am pulling away from services like Gmail, DropBox, etc. I've signed up with a few email providers, and will likely stick with 1-2 of them. ProtonMail ProtonMail is in Switzerland. They provide encrypted email, and by that I mean the contents of your emails are stored encrypted, and your connection to ProtonMail is encrypted. Your emails are decrypted in your browser, so that's the only place where anything can be read. Emails sent to other ProtonMail users are of course encrypted, but what about sending an email to someone outside of ProtonMail? Well, what happens is when the email from ProtonMail is sent, it actually just sends a special link back to ProtonMail, to where the email can be read if you have the password. Where do you get the password to read this email? That's where you have to have agreed to a password with the person who sent the email to you. A little bit cumbersome, at least the first time, but otherwise it works well. Regular, unencrypted emails can still be sent to you, so you can stil get regular email sent to you, but at least once it's in ProtonMail's system, it's safe. I've also found the Android client (currently in beta) to work well. Tutanota Tutanota is in Germany. Like ProtonMail, they provide end-to-end encrypted email. They use the same mechanism as ProtonMail, ie a link is sent to where the encrypted email can be read, as long as you have the password. So far I like both of these services. The provide both a free option as well as a paid version that provides more storage space (and that oh-so-good feeling of helping to support what are worthy businesses). I'm also trying out whiteout.io and openmailbox . I'll keep gmail around, if only for having a junk email address. Next up: Finding a replacement for DropBox.","url":"goodbye-gmail.html","title":"Goodbye Gmail"},{"tags":"Programming","text":"The text editor for those who want speed and features. I've been a long-time user of vim (and have dabbled with emacs). But it's really only been the last 2-3 years that I have make a serious commitment to learning more of vim's features. I thought I had gotten my vim configuration to where I didn't need any further changes (ahahaha). Then I began to feel like vim was slowing down. Trying to run lint checkers would cause vim to block. What I wanted in an editor, vim no longer seemed to have. Emacs began to look like an option… About a year ago, I helped support a vim fork - neovim . It's goals were to clean up large portions of the vim code, and put asynchronous support in (among other features). Well, fast-forward to this month, and I've switched to using neovim completely. Surprisingly, I now use fewer plugins, but with greater effect. Neovim feels consistently faster than vim, and some of the quirks with screen redraws seem to be gone in neovim. The neomake plugin that allows for asynchronous tasks is awesome. Running python linters in the background is faster than running them in vim ever was. It's impressive how much better neovim is than vim. One of the additional features - a built in terminal - is something I thought I wouldn't use, since I start everything within tmux sessions, but I was wrong. Being able to pull in text from the terminal straight into neovim is something I have quickly become used to having available. If you've ever tried using vim, or you are a very experienced vim user, give neovim a try. It's much faster, has additional features and it supports almost all of the existing vim plugins.","url":"neovim.html","title":"Neovim"},{"tags":"Programming","text":"I've been investing time in a few different technologies and programming languages lately. One of the languages that has surprised me is Scala. I'd heard about it, even took a peek at it many years ago, and promptly went on to other things. However, after meeting with Jeremy Pierre (noisycode.com/) from HootSuite, I decided to take another look at it. Scala has come a long way, and it seems to be poised for some real growth. I began with the usual, a quick google, wandering through some scala dedicated sites, StackOverflow and Reddit posts. I came across a course on Coursera (already signed up), and have begun reading Cay Horstmann's Scala for the Impatient. Scala makes you wish this is what Java had turned into. Scala runs on top of the JVM , so it's doing what the JVM + Java would be capable of, if only Java had gone towards this path. I think what has surprised me most about Scala so far, are the parts that seem like Perl to me. I know, shocking right? Scala similar to Perl? Scala has much higher information density that Java - you get more done per line of code. I always found Perl to have a high information density too. Quite often, Scala will infer what ‘type' you want. You can declare values as lazy (which is one of the features the Perl Moose framework provides) I've only just begun with Scala, and my views may very well change as I learn more about it. For now, it seems like an interesting (but growing) niche. There is a Vancouver meetup group - Vancouver Scala . Hopefully there will be some meetups and presentations there soon.","url":"a-side-of-scala.html","title":"A side of Scala"},{"tags":"Learning","text":"The first, and obvious: a new blog layout. In fact, I am moving this blog to github (and will change devslant.com to point to it shortly). In addition, I've decided not to keep all the previous blog posts, though they could be imported fairly easily. Career Change This week marks the first week I am no longer at airG . It was a great run over 8 years (with ups and downs), but now I am looking for a new adventure! And if anything, the field of software development has only gotten more exciting. Last year was when I really took an interest in the whole nosql area, along with node.js. This year is MOAR ! I expect Perl is not what I will end up working with any longer, at least not for a majority of the software most companies want developed. The JVM -based languages look really interesting, I recently picked up ‘Land of Lisp', and may even do some old-school C again. I find more and more that I want to know the features of most languages, and be able to use a mix, with a concentration of one or two. As an example of the awesome things to progress further with (and I will blog about): CassandraDB Couchbase 2.x FoundationDB elasticsearch logstash Storm ZooKeeper Virtualization Algorithms M2M (Machine-to-Machine) There are also several key papers that I have been reading (and will blog these too): Unified Logging Infrastructure for Data Analytics at Twitter Volcano - An Extensible and Parallel Query Evaluation System Sagas Bigtable: A Distributed Storage System for Structured Data Dynamo: Amazon's Highly Available Key-value Store There are many others of course, this is just part of my initial list.","url":"time-for-a-change.html","title":"Time for a Change"},{"tags":"Programming","text":"Lately I've been trying out Cassandra @ work. Just recently I took a webinar that DataStax hosted (the commercial company behind Cassandra), and conducted by Tim Berglund ( @tlberglund ). The webinars introduce Cassandra for developers and operations. A great way to get started understanding what Cassandra does, and doesn't do. (Tim's training videos on O'Reilly are excellent by the way). Cassandra is a schema-less, scalable, distributed database. There's actually more to it than that, but the list of it's capabilities is rather long :-). Surprisingly, it's also relatively easy to setup. I found the setup process simpler than earilier versions of MySQL, yet you get far more from a brief configuration. Single node setup Setting up a single node of Cassandra is straight forward, but it is handy to have some notes in one place, since there may be some additional files you need to download if you want some of the features provided by the OpsCenter package that DataStax makes available for monitoring your Cassandra cluster. More about that later. First, decide if you want the Apache version (no OpsCenter available with this version) or the DataStax Community version. Cassandra runs on the JVM , so make sure you have a version of the Java runtime environment. I've tested with both Oracle Java 6 & 7. The OpenJDK is not recommended. One caveat about Java 7 below. I'll be using the DataStax Community edition, which at this time is v1.1.0. Once you've downloaded the version for your OS , go ahead and install it. I'm using the tarball: dsc-cassandra-1.1.0-bin.tar.gz Configuration Edit your conf/cassandra.yaml file. initial_token You can set this to 0 for a single node, but read the notes below if you setup a cluster. directories Decide where you want your data files, commit log, and cache to be saved to. Needs to be a path you have permissions to read/write. seeds, listen_address, rpc_address You can leave these as the defaults, but you'll want to change these for cluster configurations. Java 7 Depending on the version of Cassandra you are running with Java 7, the initial amount of memory set for the stack space appears to be too small. (it works fine with v1.1.0). However, if you run into an error from the JVM about memory, change the following line in conf/cassandra-env.sh (near line 153): JVM_OPTS=\"$JVM_OPTS -Xss128k\" and change it to JVM_OPTS=\"$JVM_OPTS -Xss160k\" At this point, you can go ahead and try running Cassandra: bin/cassandra -f This will run it in the foreground, allowing you to see any errors. If you scroll through the output, you will see two items not available: … JNA not found. Native methods will be disabled. … Will not load MX4J , mx4j-tools.jar is not in the classpath These features ( JNA and mx4j) can be downloaded and installed to the cassandra/lib path by getting them from: http://sourceforge.net/projects/mx4j/files/ https://github.com/twall/jna You need the mx4j-tools.jar from the mx4j project. You need the jna.jar and platform.jar for JNA support. Once you have the jar files copied, stop and then restart Cassandra. Assuming no errors, at this point you have a working Cassandra node. You can go ahead and create a keyspace (database), and column families (tables). Cluster setup This is mostly a repeat of the single node setup. Install and configure Cassandra on your other nodes, but this time you will be filling in the config section for ‘seeds' by adding a few of the IPs from the other nodes. This allows the nodes to start talking to each other, and learn the topology of the network. You don't need to include all the other nodes, just enough for the cluster to start talking to itself. initial_token You really want to set the inital_token for each node you are installing to. As noted in the conf file, poorly chosen tokens will lead to hotspots for your data. There is a site available for generating tokens depending on the number of nodes you have here . seeds As mentioned above, you will want to add some of the IP addresses of the other nodes (even if those nodes are simply running in a virtual machine). Modify this line, and make sure the list of IPs is within the quotes: seeds: \"192.168.10.100, 192.168.10.101, 192.168.10.103\" listen_address: Set this to the local host IP address (the address that you will be configuring some of the other nodes to talk to). rpc_address: I set this to the same IP as I'm using for the listen_address - the local host IP . Ready At this point, the node is ready to become part of a cluster. You will need to perform all of the single node and cluster setup as described above on each node that you want as part of the cluster. Go ahead and start up your Cassandra instances. OpsCenter Take a look at this: Download the OpsCenter . This is pretty cool. The OpsCenter is your dashboard, allowing you to setup, modify, observe and maintain your Cassandra cluster. OpsCenter setup There are two parts to the OpsCenter, as far as configuration goes: The OpsCenter itself The agent that sends data to the OpsCenter You only need the OpsCenter running on one server, but you need the agent running on each node, so that it can feed information to the OpsCenter. conf/opscenterd.conf Set the interface value to your local host IP I also turned off ssl, since I'm just setting this up as a test cluster using several virtual machines, by adding this under [agents]: [agents] use_ssl = false agent/conf/address.yaml You can create this by running the bin/setup program, but for a simple entry, you can just create it yourself. One difference here, will be the ‘stomp_interface' - this is the IP address of the server where you want to run the OpsCenter. The agents on all nodes should be using the same OpsCenter IP address to talk to. Also note that here also, I've turned off ssl. stomp_interface: \"192.168.10.100\" use_ssl: 0 You will need to setup the agent configuration on each node. Then run the agent: agent/bin/opscenter-agent -f To turn on the OpsCenter: bin/opscenter -f Then use your browser to connect to the IP address that you configured OpsCenter to use, via port 8888. If all has gone well, at this point you have Cassandra and OpsCenter up and running, and you can see your cluster. Time to start creating keyspaces (databases) and column families (tables). Then look into CQL :-). I also recommend the #cassandra channel on freenode for questions, and the documentation on the DataStax site is extensive. Hope this helps.","url":"introducing-cassandra.html","title":"Introducing Cassandra"},{"tags":"Programming","text":"One of the things that started happening @work in the last year is that more developers within the company began looking to use a wider (and more recent) selection of technology. @work has been running for years on a LAMP (Linux, Apache 1.3x, MySQL, Perl) stack. With a move to JavaScript, HTML5 , and CSS3 for front-end development, and node.js for some of the back-end infrastructure, there have been opportunities to try new languages, databases, caches, etc. Like any group of people picking new technology, sometimes you pick wisely. Other times… When you don't know what your choice means About 8 months ago, one project team was facing a high volume of reads (and a fairly high volume of writes). They decided to try using MongoDB for storing their data. They went through some rough outages, but managed to persevere and got it working (and it still works). However, sometimes success makes everything look like it can be solved the same way. There were some features that were meant only for paying users. This is where things quickly got painful. They used MongoDB to also store whether or not the user had paid, and should therefore be granted access to additional content and features. There was already a billing system that stored this information, but they wanted to cache the billing access in MongoDB. Some of you will already be thinking of the ways this can go wrong, but for now I'm not going to focus on the risks of having data and responsibilities being duplicated across different platforms. Instead I'll focus on the disadvantage of using MongoDB for this. In this particular use case, with MongoDB's eventual consistency, users could have successfully paid, but depending on which MongoDB node the requests came to immediately after purchasing, the node may or may not have the updated data. MongoDB isn't where you want to store this kind of information. You need your view of billing data to be consistent 100% of the time. Imagine if you occasionally lost access to your TV channels because the system storing your billing state wasn't consistent. People don't like it when you mess up the access they have paid for. Speed and consistency Since it was now impacting users for something they had paid for, I became involved from the billing side of @work. Myself and another developer (from the Integrations team) volunteered to take care of it. We were faced with a few problems: The technical - data needed to be accessed frequently (about 4,000 - 5,000 queries per second with higher volumes expected), and had to be consistent each time. There was no documentation on what had been done or how the product was supposed to work. Argh. Fortunately, the actual amount of data to store was small, and could easily fit into memory. This is where we could have used memcache. We already had memcache in use in other areas of the company infrastructure, so it would be easy to spin up another instance. After a bit of research though, we decided to use Redis. Aside from being ridiculously fast (testing showed it capable of 100,000 queries per second on our servers), it supports storing data structures such as hashes, sets, sorted sets, and lists. Additionally, Redis was easy to work with. Compared to the rest of the code we needed to change, suddenly the data store and it's performance was no longer a concern. Redis just worked. Since moving the data over to Redis and ensuring that the billing system was responsible for updating it, I can say that Redis has been completely solid for us. Billions and billions of hits, no downtime, reasonably easy to slave and support for fail-over with persistence to disk. Our customers now have a correct, and consistent experience when using the product. Some technology can really help you across a range of problem domains (I'll blog about Cassandra for that in the future). But you should always be thinking (and testing!) about your choices, lest you end up using a shiny new hammer to solve problems that need a powerdrill.","url":"catching-up-with-the-future.html","title":"Catching up with the future"},{"tags":"Programming","text":"One of the drawbacks to not having an actual Android phone (for now) is that I want to see what apps are available, but Google only has a sampling of what's available on their web site . I find that rather annoying. Of course, I do have the emulator, and in theory I should be able to do something with that. The emulator does not come with Market access, but there are system images of the virtual devices for v1.5 and 1.6. I have the v1.5, and it's ok, but I wanted to see what was available for v2.2, which now has 36% of all Android users on it. I ended up using a ROM image from modaco for the nexus one (note: link may require registration). So here's how it all comes together (note, I am using Windows below, but it's nearly identical under Mac or Linux): Create an Android 2.2 AVD Copy the system.img that comes with the Android SDK to your new AVD folder. ex: D:\\android-sdk-windows\\platforms\\android-8\\images\\system.img to C:\\Users\\drodger\\.android\\avd\\AndMarket22.avd\\ Now you'll need to start the emulator, but you need to tell it how much internal storage to use (the default isn't enough). In the AVD manager, select the New… button by the Hardware section, and scroll down and select the Device ram size property, and then edit the value to 128 (just click on the value). Here's the command line version: D:\\android-sdk-windows\\tools\\emulator -avd AndMarket22.avd -partition-size 128 Wait. Wait some more. The emulator is slow to load this one up sometimes. Don't bother with the next step until the emulator has completely started. Now you need to get the build.prop file from within the emulator image, and make a change, and push the change back, like so: D:\\android-sdk-windows\\tools\\adb pull /system/build.prop Now edit that file (it will now be in your tools\\ directory), and comment out the following line by putting a ‘#' at the beginning of the line: ro.config.nocheckin=yes #ro.config.nocheckin=yes Now you need to push it back: D:\\android-sdk-windows\\tools\\adb remount D:\\android-sdk-windows\\tools\\adb push build.prop /system/build.prop Now you need the ROM you downloaded from modaco Look within the zip, in the \\system\\app folder Copy GoogleServicesFramework.apk and Vending.apk to your tools\\ directory. D:\\android-sdk-windows\\tools\\adb push GoogleServicesFramework.apk /system/app D:\\android-sdk-windows\\tools\\adb push Vending.apk /system.app Remove the SDK setup package: D:\\android-sdk-windows\\tools\\adb shell rm /system/app/SdkSetup.apk Close the emulator Delete these files in your AVD directory: cache.img, userdata.img, userdata-qemu.img Ok, now go start the emulator again, and you should be good to go!","url":"android-emulator-22-and-android-market.html","title":"Android Emulator 2.2 and Android Market"}]}